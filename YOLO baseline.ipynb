{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316f4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25996ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_yolov5(source):\n",
    "\n",
    "    # put the image in square big enough\n",
    "    col, row, _ = source.shape\n",
    "    _max = max(col, row)\n",
    "    resized = np.zeros((_max, _max, 3), np.uint8)\n",
    "    resized[0:col, 0:row] = source\n",
    "    \n",
    "    # resize to 640x640, normalize to [0,1[ and swap Red and Blue channels\n",
    "    result = cv2.dnn.blobFromImage(resized, 1/255.0, (640, 640), swapRB=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def unwrap_detection(input_image, output_data):\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    rows = output_data.shape[0]\n",
    "\n",
    "    image_width, image_height, _ = input_image.shape\n",
    "\n",
    "    x_factor = image_width / 640 + abs(image_width - image_height) / 640\n",
    "    y_factor =  image_height / 640\n",
    "\n",
    "    for r in range(rows):\n",
    "        row = output_data[r]\n",
    "        confidence = row[4]\n",
    "        if confidence >= 0.4:\n",
    "\n",
    "            classes_scores = row[5:]\n",
    "            _, _, _, max_indx = cv2.minMaxLoc(classes_scores)\n",
    "            class_id = max_indx[1]\n",
    "            if (classes_scores[class_id] > .25):\n",
    "\n",
    "                confidences.append(confidence)\n",
    "\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "                x, y, w, h = row[0].item(), row[1].item(), row[2].item(), row[3].item() \n",
    "                left = int((x - 0.5 * w) * x_factor)\n",
    "                top = int((y - 0.5 * h) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "                boxes.append(box)\n",
    "\n",
    "    return class_ids, confidences, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1921f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ncars(model, frame, labels, draw=False):\n",
    "    target_labels = ['car', 'truck', 'bus', 'motorbike']\n",
    "    blob = format_yolov5(frame)\n",
    "    model.setInput(blob)\n",
    "    outputs = model.forward()[0]\n",
    "    class_ids, confidences, boxes = unwrap_detection(frame, outputs)\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.25, 0.45)\n",
    "    \n",
    "    result_class_ids = []\n",
    "    result_confidences = []\n",
    "    result_boxes = []\n",
    "\n",
    "    for i in indexes:\n",
    "        result_confidences.append(confidences[i])\n",
    "        result_class_ids.append(class_ids[i])\n",
    "        result_boxes.append(boxes[i])\n",
    "        \n",
    "    n_cars = 0\n",
    "    for i, class_id in enumerate(result_class_ids):\n",
    "        if labels[class_id] in target_labels:\n",
    "            n_cars+=1\n",
    "    \n",
    "        if draw:\n",
    "            colors = [(255, 255, 0), (0, 255, 0), (0, 255, 255), (255, 0, 0)]\n",
    "            box = result_boxes[i]\n",
    "            class_id = result_class_ids[i]\n",
    "            if labels[class_id] in target_labels:\n",
    "                color = colors[class_id % len(colors)]\n",
    "\n",
    "                conf  = result_confidences[i]\n",
    "\n",
    "                cv2.rectangle(frame, box, color, 2)\n",
    "                cv2.rectangle(frame, (box[0], box[1] - 20), (box[0] + box[2], box[1]), color, -1)\n",
    "                cv2.putText(frame, labels[class_id], (box[0] + 5, box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0))\n",
    "    return n_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vids/light1.mp4')\n",
    "labels = open('names').read().splitlines()\n",
    "model = cv2.dnn.readNet('yolov5s.onnx')\n",
    "n_cars = []\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        n_cars.append(get_ncars(model, frame, labels, draw=True))\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a463623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
