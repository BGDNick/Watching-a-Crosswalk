{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17df236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.measure import LineModelND, ransac\n",
    "from copy import deepcopy\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f455481",
   "metadata": {},
   "source": [
    "# Some of my functions just skip it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71dc2f0",
   "metadata": {},
   "source": [
    "# Functions from Compare Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81839918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameBuffer:\n",
    "    def __init__(self, delta = 5, period = 2000):\n",
    "        self.data = []\n",
    "        self.delta = delta\n",
    "        self.period = period\n",
    "        self.maxLen = period/delta\n",
    "        self.len = 0\n",
    "    def store(self, frame):\n",
    "        self.data.append(frame)\n",
    "        self.len+=1\n",
    "        if self.len>self.maxLen:\n",
    "            self.data = self.data[1:]\n",
    "            self.len-=1\n",
    "    def express(self, distance):\n",
    "        if distance//self.delta>self.len-2:\n",
    "            out = self.data[0], self.data[-1]\n",
    "        else:\n",
    "            out = self.data[-1-distance//self.delta], self.data[-1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5763baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectedObject:#thread unsafe private class\n",
    "    def __init__(self, x1, y1, x2, y2, time):\n",
    "        self.x1, self.y1, self.x2, self.y2 = x1, y1, x2, y2\n",
    "        self.center = (np.array([x1, y1], dtype='float64')+ np.array([x2, y2], dtype='float64'))/2#[(x1+x2)/2, (y1+y2)/2]\n",
    "        self.xyxy_story =[[[self.x1, self.y1],[self.x2, self.y2]]]\n",
    "        self.center_story = [self.center]\n",
    "        self.time = [time]\n",
    "    def update(self, x1, y1, x2, y2, time):\n",
    "        self.x1, self.y1, self.x2, self.y2 = x1, y1, x2, y2\n",
    "        self.center = (np.array([x1, y1])+np.array([x2, y2]))/2\n",
    "        self.xyxy_story.append([[self.x1, self.y1],[self.x2, self.y2]])\n",
    "        self.center_story.append(self.center)\n",
    "        self.time.append(time)\n",
    "    def print(self):\n",
    "        print('xyxy       :', self.x1, self.y1, self.x2, self.y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d83718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectStore:\n",
    "    def __init__(self):\n",
    "        self.data = [] #iteration on it without mutex is thread unsafe\n",
    "        self.deleted_data = []\n",
    "        self.thresh = 0.5\n",
    "        self.time = None\n",
    "    def print(self):\n",
    "        k = 0\n",
    "        for i in self.data:\n",
    "            print('######', k, '######')\n",
    "            k+=1\n",
    "            i.print()\n",
    "        \n",
    "        print('######END######')\n",
    "    def find(self, x1, y1, x2, y2):#private function\n",
    "        r = None\n",
    "        for i in self.data:\n",
    "            xx1 = max(x1, i.x1)\n",
    "            xx2 = min(x2, i.x2)\n",
    "            yy1 = max(y1, i.y1)\n",
    "            yy2 = min(y2, i.y2)\n",
    "            xxx1 = min(x1, i.x1)\n",
    "            xxx2 = max(x2, i.x2)\n",
    "            yyy1 = min(y1, i.y1)\n",
    "            yyy2 = max(y2, i.y2)\n",
    "            ww = xx2-xx1\n",
    "            hh = yy2-yy1\n",
    "            w = xxx2-xxx1\n",
    "            h = yyy2-yyy1\n",
    "            #print(ww, hh, w, h, ww*hh/(w*h))\n",
    "            if ww<=0 or hh<=0:\n",
    "                continue\n",
    "            if ww*hh/(w*h)>self.thresh:\n",
    "                return i, True\n",
    "        return None, False\n",
    "    def store(self, x1, y1, x2, y2, time):\n",
    "        self.time = time\n",
    "        i, F = self.find(x1, y1, x2, y2)\n",
    "        if F:\n",
    "            i.update(x1, y1, x2, y2, time)\n",
    "        else:\n",
    "            i = DetectedObject(x1, y1, x2, y2, time)\n",
    "            self.data.append(i)\n",
    "    def delete_old(self,delta=5):\n",
    "        to_del = []\n",
    "        centers = []\n",
    "        for i, b in enumerate(self.data):\n",
    "            if abs(b.time[-1]-self.time)>delta:\n",
    "                to_del += [i]\n",
    "                centers.append(deepcopy(b.center_story))\n",
    "        for i in sorted(to_del, reverse=True):\n",
    "            self.deleted_data +=[self.data[i]]\n",
    "            del self.data[i]\n",
    "        return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae75a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareFrame(frame, crop=False, crop_v=[0, 200, 0, 800], ksize_val=5):\n",
    "    if crop:\n",
    "        frame = frame[crop_v[0]:crop_v[1], crop_v[2]:crop_v[3]]\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    frame = cv2.GaussianBlur(src=frame, ksize=(ksize_val, ksize_val), sigmaX=0)\n",
    "    return frame\n",
    "def compareFrames(frame1, frame2, dilate=True, dil_val=5, erode=True, erode_val=5, thresh_val=30):\n",
    "    diff = cv2.absdiff(src1=frame1, src2=frame2)\n",
    "    #cv2.imshow('Diff',diff)\n",
    "    #diff = cv2.adaptiveThreshold(diff,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    #        cv2.THRESH_BINARY,171,25)\n",
    "    #cv2.imshow('Adaptive',diff)\n",
    "   # _,diff_ = cv2.threshold(diff,100,255,cv2.THRESH_BINARY)\n",
    "    #cv2.imshow('Binary',diff)\n",
    "    if dilate:\n",
    "        kernel = np.ones((dil_val, dil_val))\n",
    "        diff = cv2.dilate(diff, kernel, 1)\n",
    "        #cv2.imshow('Dilate',diff)\n",
    "    if erode:\n",
    "        kernel = np.ones((erode_val, erode_val))\n",
    "        diff = cv2.erode(diff, kernel, 1)\n",
    "        #cv2.imshow('Erode',diff)\n",
    "    diff = cv2.threshold(src=diff, thresh=thresh_val, maxval=255, type=cv2.THRESH_BINARY)[1]\n",
    "    contours, _ = cv2.findContours(image=diff, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return diff, contours\n",
    "def filterContours(contours, area_val=5, wh_val=10):\n",
    "    con_f = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < area_val:\n",
    "            continue\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if w*h<wh_val:\n",
    "            continue\n",
    "        con_f.append(contour)\n",
    "    return con_f\n",
    "def drawContours(im, contours, crop=False, crop_v=[0, 200, 0, 800], color=(0, 255, 255), thickness=1, with_rectangles=False, color_rectangles=(255,0,255), thickness_rectangles=2):\n",
    "    if crop and (crop_v[0]!=0 or crop_v[2]!=0):\n",
    "        contours = contours.copy()\n",
    "        for contour in contours:\n",
    "            contour += [crop_v[0], crop_v[2]]\n",
    "    cv2.drawContours(image=im, contours=contours, contourIdx=-1, color=color, thickness=thickness, lineType=cv2.LINE_AA)\n",
    "    if with_rectangles:\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(img=im, pt1=(x, y), pt2=(x + w, y + h), color=color_rectangles, thickness=thickness_rectangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03892ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_frames(prev, curr, out, objectStore, time, area_val=50, wh_val=100,  crop=False, crop_v=[0, 200, 0, 800], draw=True, color=(0, 255, 255), color_super=(0, 0, 0), thickness=1, with_rectangles=False, color_rectangles=(255,0,0), thickness_rectangles=2):\n",
    "    prev, curr = prepareFrame(prev, crop=crop, crop_v=crop_v, ksize_val=3), prepareFrame(curr, crop=crop, crop_v=crop_v, ksize_val=3)\n",
    "    diff, cnt = compareFrames(prev, curr, dilate=True, dil_val=31, erode=True, erode_val=31, thresh_val=25)\n",
    "    con_f = filterContours(cnt, area_val=area_val, wh_val=wh_val)\n",
    "    for contour in con_f:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            objectStore.store(x, y, x+w, y+h, time)\n",
    "    if draw:\n",
    "        drawContours(out, con_f, crop=crop, crop_v=crop_v, color=color, thickness=thickness, with_rectangles=with_rectangles, color_rectangles=color_rectangles, thickness_rectangles=thickness_rectangles)\n",
    "    return con_f, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88295a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawObjectRectangles(pic, objectStore):\n",
    "    for b in objectStore.data:\n",
    "        cv2.rectangle(pic, pt1=(int(b.x1), int(b.y1)), pt2=(int(b.x2), int(b.y2)), color=(0, 255, 0), thickness=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720626e5",
   "metadata": {},
   "source": [
    "# Functions to projects detected cars speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81d858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf8c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(video, num_frames=50):\n",
    "    frames_num = video.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=num_frames)\n",
    "    frames_num = frames_num.astype('int')\n",
    "    frames = []\n",
    "    for frame_num in frames_num:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = video.read()\n",
    "        frames.append(frame)\n",
    "    backgroundFrame = np.median(frames, axis=0).astype('int')\n",
    "    return backgroundFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44fdb334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two auxilary functions\n",
    "def get_line(a, b, x_lim, y_lim=None):\n",
    "    x = np.linspace(*x_lim)\n",
    "    y = a * x + b\n",
    "    if y_lim is not None:\n",
    "        y = y[y>=y_lim[0]]\n",
    "        y = y[y<=y_lim[1]]\n",
    "    return x, y\n",
    "\n",
    "def hough_thetaro_to_ab(theta, ro):\n",
    "    a = -1 /np.tan(theta)\n",
    "    b = ro / np.sin(theta)\n",
    "    return a, b\n",
    "\n",
    "def show(img):\n",
    "    plt.figure(figsize=(16,16))\n",
    "    if len(img.shape) == 3:\n",
    "        img = img.astype('uint8')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)    \n",
    "    else:\n",
    "        plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e3c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(img, sigma=2):\n",
    "    img = img.astype('uint8')\n",
    "    if len(img.shape) == 3: \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "    edges_img = canny(gray, sigma=3)\n",
    "    \n",
    "    h_all, theta_all, ro_all = hough_line(edges_img)\n",
    "    h_selected, theta_selected, ro_selected = hough_line_peaks(h_all, theta_all, ro_all)\n",
    "    \n",
    "    ab_selected = np.array(\n",
    "        [hough_thetaro_to_ab(theta, ro)\n",
    "         for theta, ro in zip(theta_selected, ro_selected)])\n",
    "    model, inliers = ransac(ab_selected, LineModelND, min_samples=3, residual_threshold=0.05)\n",
    "    y_max, x_max = edges_img.shape\n",
    "    plt.figure(figsize = (8,5), dpi=300)\n",
    "    a_mean = 0\n",
    "    b_mean = 0\n",
    "    for i, (theta, ro) in enumerate(zip(theta_selected, ro_selected)):\n",
    "        if inliers[i]:\n",
    "            a, b = hough_thetaro_to_ab(theta, ro)\n",
    "            #plt.plot(*get_line(a, b, [0, x_max]), 'g', lw=2)\n",
    "            a_mean += a\n",
    "            b_mean += b\n",
    "    a_mean /= len(theta_selected)\n",
    "    b_mean /= len(theta_selected)\n",
    "    \n",
    "    return a_mean, b_mean, x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a66f3780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(xs, ys, dot):\n",
    "    start = np.array([xs[0], ys[0]])\n",
    "    end = np.array([xs[-1], ys[-1]])\n",
    "    if np.linalg.norm(start - end) < 0.1:\n",
    "        return dot\n",
    "    t = np.sum((dot - start) * (end - start)) / (np.linalg.norm(end - start)**2)\n",
    "    #t = max(0, min(1, t))\n",
    "    projection = start + t * (end - start)\n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8acd7c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(img, sigma=2):\n",
    "    img = img.astype('uint8')\n",
    "    if len(img.shape) == 3: \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "    edges_img = canny(gray, sigma=3)\n",
    "    \n",
    "    h_all, theta_all, ro_all = hough_line(edges_img)\n",
    "    h_selected, theta_selected, ro_selected = hough_line_peaks(h_all, theta_all, ro_all)\n",
    "    \n",
    "    ab_selected = np.array(\n",
    "        [hough_thetaro_to_ab(theta, ro)\n",
    "         for theta, ro in zip(theta_selected, ro_selected)])\n",
    "    model, inliers = ransac(ab_selected, LineModelND, min_samples=3, residual_threshold=0.05)\n",
    "    y_max, x_max = edges_img.shape\n",
    "    plt.figure(figsize = (8,5), dpi=300)\n",
    "    a_mean = 0\n",
    "    b_mean = 0\n",
    "    for i, (theta, ro) in enumerate(zip(theta_selected, ro_selected)):\n",
    "        if inliers[i]:\n",
    "            a, b = hough_thetaro_to_ab(theta, ro)\n",
    "            #plt.plot(*get_line(a, b, [0, x_max]), 'g', lw=2)\n",
    "            a_mean += a\n",
    "            b_mean += b\n",
    "    a_mean /= len(theta_selected)\n",
    "    b_mean /= len(theta_selected)\n",
    "    \n",
    "    return (a_mean, b_mean, x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "652e2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this functions with projected centers\n",
    "def get_speed(centers):\n",
    "    speed = np.array([np.linalg.norm(abs(centers[i+1] - centers[i])) for i in range(len(centers) - 1)])\n",
    "    return speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c25487e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers(cap):\n",
    "    \n",
    "    centers = []\n",
    "    \n",
    "    skip = 1\n",
    "    delta_compare = 4\n",
    "    frameBuffer = FrameBuffer(delta=skip, period=delta_compare * 3)\n",
    "    objectStore = ObjectStore()\n",
    "    crop=False\n",
    "    crop2=False\n",
    "    crop_v2 = [0, 170, 0, 1000]\n",
    "    time = 0\n",
    "    prev, curr = None, None\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        time += 1\n",
    "        if time % skip != 0:\n",
    "            continue\n",
    "        if ret == True:\n",
    "            out_pic = frame.copy()\n",
    "            frameBuffer.store(frame)\n",
    "            prev, curr = frameBuffer.express(delta_compare)\n",
    "            con_f, diff = compare_two_frames(prev, curr, out_pic, objectStore, time, area_val=1000, wh_val=2000, crop=crop2, crop_v=crop_v2, draw=True, color=(0, 255, 255), thickness=3, with_rectangles=False, color_rectangles=(255,0,255), thickness_rectangles=5)\n",
    "            \n",
    "            centers_temp = objectStore.delete_old(20)\n",
    "            if centers_temp != []:\n",
    "                centers.append(deepcopy(centers_temp))\n",
    "        elif ret == False:\n",
    "            break\n",
    "    cap.release()\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb94d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_centers(centers):\n",
    "    # Obtaining the line on which the projection will occur\n",
    "    video = cv2.VideoCapture(source)\n",
    "    background = get_background(video)\n",
    "    (a, b, x_max) = get_lines(background)\n",
    "    (xs, ys) = get_line(a, b, [0, x_max])\n",
    "    \n",
    "    # Get normal array of centers of cars\n",
    "    centers_reshaped = []\n",
    "    for step in centers:\n",
    "        for center in step:\n",
    "            if len(center) >  4: \n",
    "                centers_reshaped.append(center)\n",
    "                \n",
    "    # Project each point of centers on the line\n",
    "    centers_projected = []\n",
    "    for center in centers_reshaped:\n",
    "        temp_center = []\n",
    "        for point in center:\n",
    "            temp_center.append(project(xs, ys, point))\n",
    "        centers_projected.append(temp_center)\n",
    "         \n",
    "    speed_arr = []\n",
    "    coord_arr = []\n",
    "    for center in centers_projected:\n",
    "        center = np.array(center)\n",
    "        coord_arr.append(center.mean(axis=0))\n",
    "        speed = get_speed(center)\n",
    "        speed_arr.append(speed.mean())\n",
    "\n",
    "    coord_arr = np.array(coord_arr)\n",
    "    speed_arr = np.array(speed_arr)\n",
    "    model = LinearRegression()\n",
    "    model.fit(coord_arr, speed_arr)\n",
    "    predictions = model.predict(coord_arr)\n",
    "    err = np.array([predictions[i] - speed_arr[i] for i in range(len(predictions))])\n",
    "    std = err.std()\n",
    "    \n",
    "    return model, std, xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72b3927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jet_process_centers(centers, frame, model, std, xs, ys):\n",
    "    centers_reshaped = []\n",
    "    for center in centers:\n",
    "        # Add only arrays, which have more than 4 entries\n",
    "        if len(center) > 3:\n",
    "            centers_reshaped.append(center)\n",
    "    # Return if center_reshaped is empty\n",
    "    if len(centers_reshaped) == 0:\n",
    "        return frame\n",
    "    \n",
    "    # Project each point of centers on the line\n",
    "    centers_projected = []\n",
    "    for center in centers_reshaped:\n",
    "        temp_center = []\n",
    "        for point in center:\n",
    "            temp_center.append(project(xs, ys, point))\n",
    "        centers_projected.append(temp_center)\n",
    "        \n",
    "    speed_arr = []\n",
    "    coord_arr = []\n",
    "    for center in centers_projected:\n",
    "        center = np.array(center)\n",
    "        coord_arr.append(center.mean(axis=0))\n",
    "        speed = get_speed(center)\n",
    "        speed_arr.append(speed.mean())\n",
    "        \n",
    "    coord_arr = np.array(coord_arr)\n",
    "    speed_arr = np.array(speed_arr)\n",
    "    \n",
    "    predictions = model.predict(coord_arr)\n",
    "    err = np.array([(speed_arr[i] - predictions[i]) for i in range(len(predictions))])\n",
    "    \n",
    "    plot_red = []\n",
    "    plot_yellow = []\n",
    "    for ind, error in enumerate(err):\n",
    "        if error >= 3 * std:\n",
    "            plot_red.append(coord_arr[ind].astype('int'))\n",
    "        elif error >= 2 * std:\n",
    "            plot_yellow.append(coord_arr[ind].astype('int'))\n",
    "    for red in plot_red:\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (red[0]-150, red[1]-150), (red[0]+150, red[1] + 150), (0,0,255), -1)\n",
    "        alpha = 0.4\n",
    "        frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "    for yellow in plot_yellow:\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (yellow[0]-150, yellow[1]-150), (yellow[0] + 150, yellow[1] + 150), (0,255,255), -1) \n",
    "        alpha = 0.4\n",
    "        frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69007e8",
   "metadata": {},
   "source": [
    "# Centers extraction from video \"centers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1f99c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './vids/light1.mp4'\n",
    "video = cv2.VideoCapture(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "861df527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centers of detected cars from video\n",
    "centers = get_centers(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a691751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, std, xs, ys = process_centers(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ee35de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './vids/light1.mp4'\n",
    "cap = cv2.VideoCapture(source)\n",
    "skip = 1\n",
    "delta_compare = 4\n",
    "frameBuffer = FrameBuffer(delta=skip, period=delta_compare * 3)\n",
    "objectStore = ObjectStore()\n",
    "crop=False\n",
    "crop2=False\n",
    "crop_v2 = [0, 170, 0, 1000]\n",
    "time = 0\n",
    "prev, curr = None, None\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    time += 1\n",
    "    if time % skip != 0:\n",
    "        continue\n",
    "    if ret == True:\n",
    "        out_pic = frame.copy()\n",
    "        frameBuffer.store(frame)\n",
    "        prev, curr = frameBuffer.express(delta_compare)\n",
    "        con_f, diff = compare_two_frames(prev, curr, out_pic, objectStore, time, area_val=1000, wh_val=2000, crop=crop2, crop_v=crop_v2, draw=True, color=(0, 255, 255), thickness=3, with_rectangles=False, color_rectangles=(255,0,255), thickness_rectangles=5)\n",
    "        out_pic = frame.copy()\n",
    "        centers_temp = objectStore.delete_old(20)\n",
    "        if centers_temp != []:\n",
    "            out_pic = jet_process_centers(centers_temp, out_pic, model, std, xs, ys)\n",
    "        cv2.imshow('Frame', out_pic)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    elif ret == False:\n",
    "        break\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
